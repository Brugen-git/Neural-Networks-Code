{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoD+qcIwKBR90Qz6PlchK5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brugen-git/Neural-Networks-Code/blob/main/AND_MATRIX_USING_MP_NEURON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMY20i_yMbGj",
        "outputId": "32a0219f-8d7d-45c9-a30a-74d972125e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0], [1, 0], [0, 1], [1, 1]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np # helps with the math\n",
        "import matplotlib.pyplot as plt # to plot error during training\n",
        "\n",
        "# weights for the neuron\n",
        "w1 = 1\n",
        "w2 = 0\n",
        "# threshold\n",
        "theta=1\n",
        "\n",
        "# input data\n",
        "OR_Matrix = [\n",
        "        [0, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 1]\n",
        "    ]\n",
        "print(OR_Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights=np.array([w1,w2])\n",
        "print(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnIdIl_zNS1G",
        "outputId": "2c60a49b-7703-4754-89bb-4ad109ae29d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dot= OR_Matrix @ weights\n",
        "print(dot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHohcgKTWxTd",
        "outputId": "9c313efa-0ea7-448d-eb92-136a097a1bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sigmoid Activation function\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Sigmoid derivative for backpropagation\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return x * (1 - x)\n",
        "\n",
        "# Initialzing input and output values - as in XOR table\n",
        "\n",
        "# input parameters\n",
        "inputs = np.array([[0, 0],\n",
        "                  [0, 1],\n",
        "                  [1, 0],\n",
        "                  [1, 1]])\n",
        "\n",
        "# output parameters\n",
        "outputs = np.array([[0], [1], [1], [1]])\n",
        "\n",
        "# Feed Forward network\n",
        "\n",
        "def forward_pass(inputs, hidden_weights, hidden_bias, output_weights, output_bias):\n",
        "\n",
        "  hidden_layer_activation = np.dot(inputs, hidden_weights)\n",
        "  hidden_layer_activation += hidden_bias\n",
        "\n",
        "  hidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "\n",
        "  output_layer_activation = np.dot(hidden_layer_output, output_weights)\n",
        "  output_layer_activation += output_bias\n",
        "\n",
        "  predicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "  return predicted_output, hidden_layer_output\n",
        "\n",
        "# Backward propagation step\n",
        "\n",
        "def backward_pass(expected_output, predicted_output, output_weights, hidden_layer_output):\n",
        "\n",
        "  error = expected_output - predicted_output\n",
        "\n",
        "  d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
        "\n",
        "  error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "  d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "  return d_predicted_output, d_hidden_layer\n",
        "\n",
        "# Setting hyperparamters\n",
        "\n",
        "# initializing learning rate\n",
        "lr = 0.1\n",
        "\n",
        "# total epochs\n",
        "epochs = 15000\n",
        "\n",
        "# we'r taking 2 hidden layer neuron since XOR couldn't be solved using single decision plane\n",
        "# 1 output layer neuron for single output\n",
        "# 2 input layer neuron to pass 2 inputs to the Gate (0/1)\n",
        "\n",
        "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2, 2, 1\n",
        "\n",
        "# Training Neural Network\n",
        "\n",
        "def train(epochs, lr, inputs, inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons):\n",
        "\n",
        "  # Initializing random weights and biases for training\n",
        "\n",
        "  hidden_weights = np.random.uniform(size=(inputLayerNeurons, hiddenLayerNeurons))\n",
        "\n",
        "  hidden_bias =np.random.uniform(size=(1, hiddenLayerNeurons))\n",
        "\n",
        "  output_weights = np.random.uniform(size=(hiddenLayerNeurons, outputLayerNeurons))\n",
        "\n",
        "  output_bias = np.random.uniform(size=(1, outputLayerNeurons))\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # forward pass\n",
        "    predicted_output, hidden_layer_output = forward_pass(inputs, hidden_weights, hidden_bias, output_weights, output_bias)\n",
        "\n",
        "    # backward pass\n",
        "    d_predicted_output, d_hidden_layer = backward_pass(outputs, predicted_output, output_weights, hidden_layer_output)\n",
        "\n",
        "    #Updating Weights and Biases\n",
        "    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
        "\n",
        "    output_bias += np.sum(d_predicted_output, axis=0, keepdims=True) * lr\n",
        "\n",
        "    hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
        "\n",
        "    hidden_bias += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "      print(f\"Training.... epoch: {epoch}\")\n",
        "    if epoch == (epochs - 1):\n",
        "      print('\\nTraining completed!')\n",
        "      \n",
        "  return predicted_output\n",
        "\n",
        "predicted_output = train(epochs, lr, inputs, inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons)\n",
        "\n",
        "# Predicted Output\n",
        "print('\\nPredicted output:')\n",
        "print(predicted_output)\n",
        "\n",
        "print('\\n Round value of the predicted labels:\\n')\n",
        "for val in predicted_output:\n",
        "  print(np.round(val))\n",
        "\n",
        "# Random data of 100Ã—3 dimension\n",
        "data = np.array(np.random.random((int(val))))\n",
        "\n",
        "# Scatter plot\n",
        "plt.scatter(data[0], data[1], c=data[2], cmap='hot')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "kc1CTkyMXPnY",
        "outputId": "e37e9081-7f8d-4b20-f23c-5bbca5253534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training.... epoch: 0\n",
            "Training.... epoch: 1000\n",
            "Training.... epoch: 2000\n",
            "Training.... epoch: 3000\n",
            "Training.... epoch: 4000\n",
            "Training.... epoch: 5000\n",
            "Training.... epoch: 6000\n",
            "Training.... epoch: 7000\n",
            "Training.... epoch: 8000\n",
            "Training.... epoch: 9000\n",
            "Training.... epoch: 10000\n",
            "Training.... epoch: 11000\n",
            "Training.... epoch: 12000\n",
            "Training.... epoch: 13000\n",
            "Training.... epoch: 14000\n",
            "\n",
            "Training completed!\n",
            "\n",
            "Predicted output:\n",
            "[[0.03304052]\n",
            " [0.98169658]\n",
            " [0.98189822]\n",
            " [0.99609887]]\n",
            "\n",
            " Round value of the predicted labels:\n",
            "\n",
            "[0.]\n",
            "[1.]\n",
            "[1.]\n",
            "[1.]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-1ae9927db514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# Scatter plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# Display the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FubeZj5UZ13i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}